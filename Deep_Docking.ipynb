{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "\n",
    "import subprocess #to run sh script via python\n",
    "import optuna #is used to optimize hyperparameters\n",
    "from joblib import Parallel, delayed #in parallel it is faster and order of rows is the same\n",
    "import multiprocessing \n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "##### Here we get rid of smiles, which cannot be processed by RDKit in case to avoid this issue in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_of_file = input(\"Enter path of your database, which you want to use: \") #just path, without quotes\n",
    "#\"/home/gnss/dinakh/Git/QSAR_docking/Data_base_MOL_PORT/3_2023/Screening Compounds/merged.smi\"\n",
    "print(f\"You chose '{path_of_file}' database\")\n",
    "radius= int(input(\"Enter the radius in Morgan fingerprint: \"))\n",
    "nBits= int(input(\"Enter the number of bits in Morgan fingerprint: \"))\n",
    "ecfp6_name = [f'Bit_{i}' for i in range(nBits)]\n",
    "with open(path_of_file, \"r\") as ins:\n",
    "    smiles = []\n",
    "    for line in ins:\n",
    "        smiles.append(line.split('\\n')[0]) #convert a smiles format to the list, where which line of smile has its own row\n",
    "print(f\"Number compounds in your database '{len(smiles[1:])}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_compounds = input(\"Enter a number of compounds, which you want to sample on the first iteration: \") \n",
    "print(f\"You chose '{number_of_compounds}' compounds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smiles_initial = pd.DataFrame(smiles[1:], columns=['smile'])\n",
    "df_smiles_initial.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_right = []\n",
    "bad_values = []\n",
    "ECFP = [] #Extended Connectivity Fingerprint (ECFP)\n",
    "\n",
    "for i in list(df_smiles_initial.index.values):\n",
    "    try:\n",
    "       list_right = Chem.MolFromSmiles((df_smiles_initial.iloc[i])['smile'])\n",
    "       ECFP.append(Chem.GetMorganFingerprintAsBitVect(list_right,radius=radius, nBits=nBits))\n",
    "    except: \n",
    "        bad_values.append(df_smiles_initial.iloc[i])\n",
    "print(f\"Number compounds did not processed by RDKit '{len(bad_values)}'\")\n",
    "\n",
    "bad_values_numeric = [] #for now it looks like a small dataframe for each compound and it is complex to reach the exact number of row \n",
    "for l in range(len(bad_values)): # so we will create a list of numbers from dataframe for convenience\n",
    "    bad_values_numeric.append(bad_values[l].name) \n",
    "df_smiles_initial.drop(bad_values_numeric, inplace = True)\n",
    "print(f\"Final number of compounds in your database '{len(df_smiles_initial)}'\")\n",
    "df_smiles_initial.to_csv('df_smiles_initial.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_sampled_to_glide_dock(x):\n",
    "    smiles_to_list = x['smile'].tolist() #for docking it should be list of smiles\n",
    "    smiles_to_list.insert(0, smiles[0]) #with the first row of names, which we take from the database\n",
    "    with open('smiles_to_prepare.smi', 'w') as f:\n",
    "        for line in smiles_to_list:\n",
    "            f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confusion_matrix(cf,    #fuction to create a nice cofusion matrix\n",
    "                          group_names=None,\n",
    "                          categories='auto',\n",
    "                          count=True,\n",
    "                          percent=True,\n",
    "                          cbar=True,\n",
    "                          xyticks=True,\n",
    "                          xyplotlabels=True,\n",
    "                          sum_stats=True,\n",
    "                          figsize=None,\n",
    "                          cmap='Blues',\n",
    "                          title=None):\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names)==cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    if percent:\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
    "    else:\n",
    "        group_percentages = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
    "\n",
    "    if sum_stats:\n",
    "        #Accuracy is sum of diagonal divided by total observations\n",
    "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
    "\n",
    "        #if it is a binary confusion matrix, show some more stats\n",
    "        if len(cf)==2:\n",
    "            #Metrics for Binary Confusion Matrices\n",
    "            precision = cf[1,1] / sum(cf[:,1])\n",
    "            recall    = cf[1,1] / sum(cf[1,:])\n",
    "            f1_score  = 2*precision*recall / (precision + recall)\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
    "                accuracy,precision,recall,f1_score)\n",
    "        else:\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
    "    else:\n",
    "        stats_text = \"\"\n",
    "\n",
    "    if figsize==None:\n",
    "        #Get default figure size if not set\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks==False:\n",
    "        #Do not show categories if xyticks is False\n",
    "        categories=False\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
    "\n",
    "    if xyplotlabels:\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label' + stats_text)\n",
    "    else:\n",
    "        plt.xlabel(stats_text)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on the whole database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_values(x, model):\n",
    "    molecula = Chem.MolFromSmiles(x)\n",
    "    bit = Chem.GetMorganFingerprintAsBitVect(molecula,radius=radius, nBits=nBits)\n",
    "    df_morgan_try  = pd.DataFrame(columns=ecfp6_name)\n",
    "    df_morgan_try.loc[0] = list(bit)\n",
    "    predictions1 = model.predict(df_morgan_try)[0]\n",
    "    return predictions1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for working after docking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def after_docking():\n",
    "    df_dock_glide = pd.read_csv(r\"glide-dock_ex.csv\")\n",
    "    print(f\"Number compounds after docking '{len(df_dock_glide)}'\")\n",
    "\n",
    "    #ligprep generates different possible charges, absolute configuration and etc., therefore eventually we got table with duplicates in title and NO duplicates in SMILES themselves\n",
    "    #however we will return to the initial database to exclude already processed compounds, so we need to keep it the same as it was \n",
    "    #we also need to get rid of compounds that were not docked because of reasons as incorrect configuration and etc. \n",
    "\n",
    "    print(f\"Number duplicates '{df_dock_glide.title.duplicated().sum()}'\")\n",
    "    print(f\"Number undocked compounds '{df_dock_glide['r_i_docking_score'].isna().sum()}'\")\n",
    "    df_dock_glide = df_dock_glide.dropna()\n",
    "\n",
    "    df_dock_glide_final = pd.DataFrame(columns = df_dock_glide.columns)\n",
    "    for x in df_dock_glide['title']:\n",
    "        data_frame_small = df_dock_glide[df_dock_glide['title'] == x]\n",
    "        min_glide_gscore = data_frame_small['r_i_docking_score'].min()\n",
    "        data_frame_small_min_score = data_frame_small[data_frame_small['r_i_docking_score'] == min_glide_gscore]\n",
    "        df_dock_glide_final= pd.concat([df_dock_glide_final, data_frame_small_min_score])\n",
    "    df_dock_glide_final_dupl = df_dock_glide_final.drop_duplicates(subset='title', keep=\"last\") #the final dataset has only one row for each title with the lowest docking score\n",
    "    print(f\"Number compounds in final dataset '{len(df_dock_glide_final_dupl)}'\")\n",
    "    #list_with_1_names = [] #here we just put the first part of smile to the dataframe with docking scores to merge them in a future\n",
    "    return df_dock_glide_final_dupl#, list_with_1_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_full_names(x):\n",
    "    data_frame_small = df_smiles_initial[df_smiles_initial['part_2'] == x]\n",
    "    part_1_score = data_frame_small['part_1'].min()\n",
    "    print(part_1_score)\n",
    "    return part_1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Right form of the file after docking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparation_of_right_form():\n",
    "    global results_after_docking\n",
    "    results_after_docking['part_1'] = part_1_lst\n",
    "    list_of_full_names = []\n",
    "    for row in results_after_docking.index:\n",
    "        new_name = results_after_docking.loc[row, 'part_1'] + '\\t' + results_after_docking.loc[row, 'title']\n",
    "        list_of_full_names.append(new_name) #after docking, the program automatically take the first part as a smile and the second as a title, so \n",
    "    results_after_docking['full_title'] = list_of_full_names #we need to return the initial name to have the same prosedure for each iteration\n",
    "    # 'full_title' is the column via we will exclude already processed compounds from the initial database\n",
    "    results_after_docking = results_after_docking[['full_title', 'r_i_docking_score']] #we will work only with a docking scores ans smiles themselves, therefore keep only these columns\n",
    "\n",
    "    ECFP = []\n",
    "    for x in results_after_docking['full_title']:\n",
    "        list_right = Chem.MolFromSmiles(x)\n",
    "        ECFP.append(Chem.GetMorganFingerprintAsBitVect(list_right,radius=radius, nBits=nBits))\n",
    "    ecfp6_bits = [list(l) for l in ECFP]\n",
    "    results_after_docking[ecfp6_name] = ecfp6_bits #only presentaion of bits where each bit located in the separate column allow keep them from iteration to iteration\n",
    "    results_after_docking.drop(results_after_docking[(results_after_docking['r_i_docking_score'] > 5)].index, inplace=True) \n",
    "    #sometimes Maestro can give us weird scores which we cannot take into account, the value 5 was chosed randomly, just based on the usual output that we get\n",
    "    return results_after_docking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "categories = ['Zero', 'One']\n",
    "number_of_iterations = 7\n",
    "iteration = 1\n",
    "cutoff = 0.1\n",
    "cutoff_numeric_for_iteration_lst = []\n",
    "MEAN_DOCK_SCORE_LST = []\n",
    "LOWEST_SCORE_LST = []\n",
    "while iteration < number_of_iterations:\n",
    "  print(f\"The iteration which you are working on: {iteration}\")\n",
    "  if iteration == 1:\n",
    "    df_initial_compounds = df_smiles_initial.sample(n=int(number_of_compounds),replace=False) #defined by user in the beginning\n",
    "    from_sampled_to_glide_dock(df_initial_compounds)\n",
    "\n",
    "\n",
    "    file_ = open('shell_output.txt', 'w+') \n",
    "    subprocess.run('sh maestro_1_iteration.sh', shell=True, stdout=file_) \n",
    "    file_.close() \n",
    "\n",
    "\n",
    "    results_after_docking = after_docking()\n",
    "    \n",
    "    list_1_part = []\n",
    "    list_2_part = []\n",
    "    for i in df_smiles_initial['smile'].to_list():\n",
    "      part_1 = i.split('\\t', 1)[0]\n",
    "      part_2 = i.split('\\t', 1)[1]\n",
    "      list_1_part.append(part_1)\n",
    "      list_2_part.append(part_2)\n",
    "    df_smiles_initial['part_1'] = list_1_part # we separate the titles in the initial database to the two part: smile that will be changed during the ligprep\n",
    "    df_smiles_initial['part_2'] = list_2_part # (and it is the only stage in which we can pull out them) and the rest part \n",
    "    \n",
    "    part_1_lst = Parallel(n_jobs=1)(delayed(return_full_names)(x) for x in results_after_docking['title']) #for now I cannot increase number of jobs, because it is run out of memory, but at least it can decrease the number of lines in the code\n",
    "    df_docking_final_table = preparation_of_right_form()\n",
    "    LOWEST_SCORE = df_docking_final_table['r_i_docking_score'].min()\n",
    "    df_docking_final_table_initial = df_docking_final_table.copy()\n",
    "\n",
    "\n",
    "    cutoff_numeric_for_iteration = df_docking_final_table['r_i_docking_score'].sort_values()[0:round(len(df_docking_final_table)*cutoff)].iloc[- 1]\n",
    "    df_docking_final_table.loc[df_docking_final_table['r_i_docking_score'] >= cutoff_numeric_for_iteration, 'r_i_docking_score'] = 0 \n",
    "    df_docking_final_table.loc[df_docking_final_table['r_i_docking_score'] < cutoff_numeric_for_iteration, 'r_i_docking_score'] = 1\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_docking_final_table.drop(['r_i_docking_score', 'full_title'], axis=1),\n",
    "                                                        df_docking_final_table['r_i_docking_score'], test_size=0.2,\n",
    "                                                        random_state=42, stratify=df_docking_final_table['r_i_docking_score'])\n",
    "    def objective(trial , X = X_train , y = y_train):\n",
    "      train_x , valid_x , train_y , valid_y = train_test_split(X , y , \\\n",
    "              test_size = 0.2 , random_state = 42, stratify = y) \n",
    "      params = {\n",
    "          'C' : trial.suggest_loguniform(\"C\", 1e-2, 1)} #Inverse of regularization strength\n",
    "      model1 = LogisticRegression(**params) # and so smaller values specify stronger regularization\n",
    "      model1.fit(train_x , train_y)\n",
    "      y_predlr = model1.predict(valid_x)\n",
    "      ll = log_loss(valid_y , y_predlr)\n",
    "      return ll\n",
    "    \n",
    "    # after the first iteration we should keep these sets (training and test) to augment them in the future\n",
    "    df_TRAIN_INITIAL = df_docking_final_table_initial.loc[X_train.index.values.tolist()]\n",
    "    df_TRAIN_INITIAL.to_csv('df_TRAIN_INITIAL.csv')\n",
    "    MEAN_SCORE = df_TRAIN_INITIAL['r_i_docking_score'].mean()\n",
    "    df_TEST_INITIAL = df_docking_final_table_initial.loc[X_test.index.values.tolist()]\n",
    "    df_TEST_INITIAL.to_csv('df_TEST_INITIAL.csv')\n",
    "    # in the first iteration we create these sets and after during the rest of itereatons we augmet them, so I suggest create a loop with if = 1 iteration : do creation, else do augmentation\n",
    "\n",
    "\n",
    "    study = optuna.create_study()\n",
    "    study.optimize(objective, n_trials=50) #number of attempts\n",
    "    best_params = study.best_params\n",
    "    found_x = best_params[\"C\"]\n",
    "    print(f\"Inverse of regularization strength ('C'):  '{found_x}'\") #the best parameter that was found and which will be used during training\n",
    "\n",
    "    logmodel = LogisticRegression(C=round(found_x, 3), solver='sag') #we round the received number in case of avoidind strong adjustment to the particular dataset \n",
    "    logmodel.fit(X_train,y_train)\n",
    "    predictions = logmodel.predict(X_test)\n",
    "    cf_matrix = confusion_matrix(y_test,predictions)\n",
    "    make_confusion_matrix(cf_matrix, \n",
    "                      group_names=labels,\n",
    "                      categories=categories, \n",
    "                      cmap='Blues')\n",
    "    \n",
    "\n",
    "    datbase_no_train_test = df_smiles_initial[~df_smiles_initial['smile'].isin(df_docking_final_table['full_title'].to_list())]\n",
    "\n",
    "    lst = Parallel(n_jobs=40)(delayed(predict_values)(x, model=logmodel) for x in datbase_no_train_test['smile']) #using parallel it takes 58min!\n",
    "    datbase_no_train_test['docking_score'] = lst\n",
    "\n",
    "\n",
    "    predicted_as_hits = datbase_no_train_test[datbase_no_train_test['docking_score'] == 1]\n",
    "    if  len(predicted_as_hits) > 5000:\n",
    "      predicted_as_hits = (predicted_as_hits[predicted_as_hits['docking_score'] == 1]).sample(n=5000,replace=False)\n",
    "\n",
    "\n",
    "  else:\n",
    "    from_sampled_to_glide_dock(predicted_as_hits)\n",
    "    file_ = open('shell_output.txt', 'w+') \n",
    "    subprocess.run('sh maestro_delete.sh', shell=True, stdout=file_) \n",
    "    file_.close() \n",
    "\n",
    "\n",
    "    results_after_docking = after_docking()\n",
    "    part_1_lst = Parallel(n_jobs=1)(delayed(return_full_names)(x) for x in results_after_docking['title']) #for now I cannot increase number of jobs, because it is run out of memory, but at least it can decrease the number of lines in the code\n",
    "    df_for_merging = preparation_of_right_form()\n",
    "    #LOWEST_SCORE = df_for_merging['r_i_docking_score'].min()\n",
    "    train_merge = df_for_merging.sample(frac = 0.8)\n",
    "    test_merge = df_for_merging.drop(train_merge.index)\n",
    "\n",
    "    df_TRAIN_INITIAL = pd.read_csv(r\"df_TRAIN_INITIAL.csv\")\n",
    "    df_TRAIN_INITIAL = df_TRAIN_INITIAL.drop(['Unnamed: 0'], axis=1)\n",
    "    df_TRAIN_INITIAL = df_TRAIN_INITIAL.append(train_merge, ignore_index=True)\n",
    "    MEAN_SCORE = df_TRAIN_INITIAL['r_i_docking_score'].mean()\n",
    "    LOWEST_SCORE = df_TRAIN_INITIAL['r_i_docking_score'].min()\n",
    "    df_TRAIN_INITIAL.to_csv('df_TRAIN_INITIAL.csv') #we need to save both sets in case to have numeric docking scores\n",
    "    df_TEST_INITIAL = pd.read_csv(r\"df_TEST_INITIAL.csv\")\n",
    "    df_TEST_INITIAL = df_TEST_INITIAL.drop(['Unnamed: 0'], axis=1)\n",
    "    df_TEST_INITIAL = df_TEST_INITIAL.append(test_merge, ignore_index=True)\n",
    "    df_TEST_INITIAL.to_csv('df_TEST_INITIAL.csv') #because after next actions they became as zeros and ones \n",
    "    #and I will also use it as output after docking protocol\n",
    "    result_after_concat = pd.concat([df_TRAIN_INITIAL, df_TEST_INITIAL], axis=0)\n",
    "    cutoff_numeric_for_iteration = df_TRAIN_INITIAL['r_i_docking_score'].sort_values()[0:round(len(df_TRAIN_INITIAL)*cutoff)].iloc[- 1]\n",
    "    df_TRAIN_INITIAL.loc[df_TRAIN_INITIAL['r_i_docking_score'] >= cutoff_numeric_for_iteration, 'r_i_docking_score'] = 0 \n",
    "    df_TRAIN_INITIAL.loc[df_TRAIN_INITIAL['r_i_docking_score'] < cutoff_numeric_for_iteration, 'r_i_docking_score'] = 1 \n",
    "    df_TEST_INITIAL.loc[df_TEST_INITIAL['r_i_docking_score'] >= cutoff_numeric_for_iteration, 'r_i_docking_score'] = 0 \n",
    "    df_TEST_INITIAL.loc[df_TEST_INITIAL['r_i_docking_score'] < cutoff_numeric_for_iteration, 'r_i_docking_score'] = 1\n",
    "    X_train = df_TRAIN_INITIAL.drop(['r_i_docking_score', 'full_title'], axis=1)\n",
    "    y_train = df_TRAIN_INITIAL['r_i_docking_score']\n",
    "    X_test = df_TEST_INITIAL.drop(['r_i_docking_score', 'full_title'], axis=1)\n",
    "    y_test = df_TEST_INITIAL['r_i_docking_score']\n",
    "\n",
    "    def objective(trial , X = X_train , y = y_train):\n",
    "      train_x , valid_x , train_y , valid_y = train_test_split(X , y , \\\n",
    "              test_size = 0.2 , random_state = 42, stratify = y) \n",
    "      params = {\n",
    "          'C' : trial.suggest_loguniform(\"C\", 1e-2, 1)} #Inverse of regularization strength\n",
    "      model1 = LogisticRegression(**params) # and so smaller values specify stronger regularization\n",
    "      model1.fit(train_x , train_y)\n",
    "      y_predlr = model1.predict(valid_x)\n",
    "      ll = log_loss(valid_y , y_predlr)\n",
    "      return ll\n",
    "\n",
    "\n",
    "\n",
    "    study = optuna.create_study()\n",
    "    study.optimize(objective, n_trials=50) #number of attempts\n",
    "    best_params = study.best_params\n",
    "    found_x = best_params[\"C\"]\n",
    "    print(f\"Inverse of regularization strength ('C'):  '{found_x}'\") #the best parameter that was found and which will be used during training\n",
    "\n",
    "    logmodel = LogisticRegression(C=round(found_x, 3), solver='sag') #we round the received number in case of avoidind strong adjustment to the particular dataset \n",
    "    logmodel.fit(X_train,y_train)\n",
    "    predictions = logmodel.predict(X_test)\n",
    "    cf_matrix = confusion_matrix(y_test,predictions)\n",
    "    make_confusion_matrix(cf_matrix, \n",
    "                      group_names=labels,\n",
    "                      categories=categories, \n",
    "                      cmap='Blues')\n",
    "\n",
    "    datbase_no_train_test = df_smiles_initial[~df_smiles_initial['smile'].isin(result_after_concat['full_title'].to_list())]\n",
    "\n",
    "    lst = Parallel(n_jobs=40)(delayed(predict_values)(x, model=logmodel) for x in datbase_no_train_test['smile']) #using parallel it takes 58min!\n",
    "    datbase_no_train_test['docking_score'] = lst\n",
    "\n",
    "\n",
    "    predicted_as_hits = datbase_no_train_test[datbase_no_train_test['docking_score'] == 1]\n",
    "    if  len(predicted_as_hits) > 5000:\n",
    "      predicted_as_hits = (predicted_as_hits[predicted_as_hits['docking_score'] == 1]).sample(n=5000,replace=False)\n",
    "  cutoff -= 0.01\n",
    "  cutoff_numeric_for_iteration_lst.append(cutoff_numeric_for_iteration)\n",
    "  MEAN_DOCK_SCORE_LST.append(MEAN_SCORE)\n",
    "  LOWEST_SCORE_LST.append(LOWEST_SCORE)\n",
    "  iteration += 1\n",
    "with open(\"cutoff_numeric_for_iteration_lst\", \"wb\") as fp:\n",
    "  pickle.dump(cutoff_numeric_for_iteration_lst, fp)\n",
    "with open(\"MEAN_DOCK_SCORE_LST\", \"wb\") as fp:\n",
    "  pickle.dump(MEAN_DOCK_SCORE_LST, fp)\n",
    "with open(\"LOWEST_SCORE_LST\", \"wb\") as fp:\n",
    "  pickle.dump(LOWEST_SCORE_LST, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
